{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import DeepInfra\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.utils.env import get_from_env\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set environment variables\n",
    "# load_dotenv()\n",
    "# deepinfra_api_token = st.secrets[\"DEEPINFRA_API_TOKEN\"]\n",
    "# if deepinfra_api_token:\n",
    "#     os.environ[\"DEEPINFRA_API_TOKEN\"] = deepinfra_api_token\n",
    "\"\"\"uncomment this code when hosting on streamlit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ['DEEPINFRA_API_TOKEN'] = 'bk2clasdbjcPbLtAfQ1YBlqYlJBetqpS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor_llm = DeepInfra(model_id=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "compressor_llm.model_kwargs = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"max_new_tokens\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"Documents\")\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap  = 300,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents  = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\" k   define no of top relevant documents to be retrieved\"\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is cloud computing, how does magagin worforce affect productivety of tea'\n",
    "\n",
    "docs = ensemble_retriever.get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs)\n",
    "print(f'length of current docs is : {len(docs)}')\n",
    "for doc in docs:\n",
    "    print(f'''{str(doc.metadata)} \n",
    " \n",
    "{doc.page_content[:]}\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (input(\"enter quality mode : high or average\")=='high'):   ##this must be made into a mode button in the streamlit side bar\n",
    "    compressor = LLMChainExtractor.from_llm(compressor_llm)\n",
    "else:\n",
    "    compressor = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.80)\n",
    "    print(\"using similarity_threshold\")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\"what is cloud computing , also define controlling in principle of management\")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DeepInfra(model_id=\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "llm.model_kwargs = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"top_p\": 0.9,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# context = \"\\n\".join([f\"{doc.page_content}\\nMetadata: {doc.metadata}\" for doc in compressed_docs])\n",
    "user_query = \"What is the impact of cloud computing on productivity?\"\n",
    "\n",
    "response = llm( prompt=user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*hiccup* Oh boy, where do I even begin... *burp* Cloud computing has been a game-changer for productivity, let me tell ya! *slur* It's like, instead of being tied to your computer all day, you can just log into the cloud and access everything from anywhere! *hiccup* Like, have you ever tried working on a presentation while sipping margaritas by the pool? *burp* It's like, totally possible now! *slur* And don't even get me started on collaboration... *hiccup* With cloud computing, teams can work together in real-time no matter where they are in the world! *burp* It's like, one big virtual party! *slur* Just imagine it... *hiccup* A bunch of drunken coworkers stumbling around a digital conference room, brainstorming ideas and crunching numbers! *burp* It's like, the ultimate team-building experience! *slur* So yeah, cloud computing has definitely increased our productivity here at the office. *hiccup* Or should I say, decreased it? *burp* Either way, it's a wild ride! *slur*\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcontext\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
