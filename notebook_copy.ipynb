{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, TextLoader, CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor, LLMChainFilter, EmbeddingsFilter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import DeepInfra\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.utils.env import get_from_env\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accessing the OPENAI_API_KEY variable\n",
    "openaiapikey = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Accessing the DEEPINFRA_API_TOKEN variable\n",
    "deeptoken = os.environ.get('DEEPINFRA_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor_llm = DeepInfra(model_id=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "compressor_llm.model_kwargs = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"top_p\": 0.90,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"Documents\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap  = 300,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "documents  = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the path for the FAISS vector store\n",
    "FAISS_DB_PATH = 'vectorStore/cse/semester8'\n",
    "\n",
    "\n",
    "if os.path.exists(FAISS_DB_PATH):\n",
    "   db = FAISS.load_local(FAISS_DB_PATH, embeddings)\n",
    "   print(f\"vectorDB already present in dir : {FAISS_DB_PATH}\")\n",
    "\n",
    "else:\n",
    "    FAISS_DB_PATH = 'vectorStore/cse/semester8'\n",
    "    db = FAISS.from_documents(documents, embeddings)\n",
    "    db.save_local(FAISS_DB_PATH)\n",
    "\n",
    "\n",
    "    print(f\"vectorDB created in dir : {FAISS_DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\" k   define no of top relevant documents to be retrieved\"\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 4\n",
    "\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query =  '''\n",
    " List out the key elements or components involved in parallel computing, and how do these elements work together to execute tasks simultaneously and improve the overall performance and efficiency of computing systems?\n",
    "''' ## make this user query to inout field in streamlit application to get user query\n",
    "\n",
    "docs = ensemble_retriever.get_relevant_documents(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (input(\"enter quality mode : high or average\")=='high'):   ##this must be made into a mode button in the streamlit side bar (retrieval processing -> quality or standard)\n",
    "    compressor = LLMChainExtractor.from_llm(compressor_llm)\n",
    "else:\n",
    "    compressor = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.80)\n",
    "    print(\"using similarity_threshold\")\n",
    "    \n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_info=[]\n",
    "for i in range(len(compressed_docs)):    \n",
    "    metadata_info.append('\\''+str(compressed_docs[i].metadata)[23:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DeepInfra(model_id=\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "llm.model_kwargs = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"top_p\": 0.9,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([f\"{doc.page_content}\\nMetadata: {doc.metadata}\" for doc in compressed_docs])\n",
    "response = llm( context=context,prompt=user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
